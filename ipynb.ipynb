{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "incident-criticism",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "invalid-round",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas==1.4.3 in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 1)) (1.4.3)\n",
      "Requirement already satisfied: matplotlib==3.5.2 in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 2)) (3.5.2)\n",
      "Requirement already satisfied: scikit-learn==1.1.1 in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 3)) (1.1.1)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib==3.5.2->-r requirements.txt (line 2)) (2.4.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.8/site-packages (from matplotlib==3.5.2->-r requirements.txt (line 2)) (0.11.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.8/site-packages (from matplotlib==3.5.2->-r requirements.txt (line 2)) (8.4.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib==3.5.2->-r requirements.txt (line 2)) (1.4.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.8/site-packages (from matplotlib==3.5.2->-r requirements.txt (line 2)) (2.8.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.8/site-packages (from matplotlib==3.5.2->-r requirements.txt (line 2)) (20.9)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.8/site-packages (from matplotlib==3.5.2->-r requirements.txt (line 2)) (4.34.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.8/site-packages (from matplotlib==3.5.2->-r requirements.txt (line 2)) (1.21.5)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.8/site-packages (from pandas==1.4.3->-r requirements.txt (line 1)) (2021.1)\n",
      "Requirement already satisfied: joblib>=1.0.0 in /opt/conda/lib/python3.8/site-packages (from scikit-learn==1.1.1->-r requirements.txt (line 3)) (1.1.0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.8/site-packages (from scikit-learn==1.1.1->-r requirements.txt (line 3)) (1.9.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from scikit-learn==1.1.1->-r requirements.txt (line 3)) (3.1.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.8/site-packages (from python-dateutil>=2.7->matplotlib==3.5.2->-r requirements.txt (line 2)) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "hispanic-reservoir",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of dataset: 95025\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "seed = 0\n",
    "\n",
    "data = pd.read_csv('name_gender.csv')\n",
    "print(f'Size of dataset: {len(data)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "former-today",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>95025</td>\n",
       "      <td>95025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>95025</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Aaban&amp;&amp;</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>60304</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           name gender\n",
       "count     95025  95025\n",
       "unique    95025      2\n",
       "top     Aaban&&      F\n",
       "freq          1  60304"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "neural-candy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().values.any() # No missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "central-gravity",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "F    60304\n",
       "M    34721\n",
       "Name: gender, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['gender'].value_counts() # Class frequencies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opening-solomon",
   "metadata": {},
   "source": [
    "# Data cleaning and preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "different-alloy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            name gender\n",
      "0        Aaban&&      M\n",
      "1         Aabha*      F\n",
      "4          Aada_      F\n",
      "10       Aadhav+      M\n",
      "13      Aadhira4      F\n",
      "...          ...    ...\n",
      "94826   Zyair770      M\n",
      "94874  Zyheir887      M\n",
      "94915    Zykir24      M\n",
      "94957  Zymirah11      F\n",
      "94995     Zyri*&      F\n",
      "\n",
      "[65 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# List of non-alphabetic names\n",
    "print(data[data['name'].str.contains('\\W|\\d|_')])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arranged-school",
   "metadata": {},
   "source": [
    "The following step removes non-alphabetic characters (numbers, symbols) from the names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "local-credits",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['name'] = data['name'].str.replace('\\W|\\d|_','',regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "sustainable-representation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset stratified by gender before tokenizing to avoid leakage of test set info into training features\n",
    "X_train, X_test, y_train, y_test = train_test_split(data['name'], data['gender'], test_size=0.1, \\\n",
    "                                                    random_state=seed, stratify=data['gender'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lesbian-auditor",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tight-analyst",
   "metadata": {},
   "source": [
    "https://arxiv.org/pdf/2102.03692.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "front-damages",
   "metadata": {},
   "source": [
    "error analysis\n",
    "\n",
    "naive bayes\n",
    "random forest\n",
    "lstm\n",
    "char-bert"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "consecutive-optimum",
   "metadata": {},
   "source": [
    "Various models will be tried. \n",
    "\n",
    "Additionally, for each model, various ways of feature engineering to create input features will be conducted as an experiment. First, a set of ngrams will be created from each name using sklearn's count vectorizer, essentially a bag of words approach before applying a machine learning model. The second method will further convert the count vectors into tf-idf vectors. The last method will involve class scaling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "violent-attack",
   "metadata": {},
   "source": [
    "Different features https://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction\n",
    "1) BOW of ngrams\n",
    "\n",
    "2) TF-IDF of ngrams\n",
    "scale down the impact of tokens that are common in a corpus and hence less informative (does it apply here?)\n",
    "\n",
    "3) Class scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "timely-wisdom",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average word length: 6\n"
     ]
    }
   ],
   "source": [
    "ngram_upper = int(np.floor(np.mean(data['name'].apply(len))))\n",
    "print(f'Average word length: {ngram_upper}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unable-saudi",
   "metadata": {},
   "source": [
    "A minimum of 2 characters and a maximum of 6 (mean word length) is used for constructing ngrams."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "secret-monster",
   "metadata": {},
   "source": [
    "For hyerparameter tuning, stratified 5-fold CV will be used. However, tokenization will only be performed after splitting the dataset in order to prevent the validation set from having any info on the features of the other training folds. This procedure will be combined with gridsearchcv using a pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "residential-chorus",
   "metadata": {},
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incident-controversy",
   "metadata": {},
   "source": [
    "### BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "still-kernel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'logisticregression__C': 0.01}</td>\n",
       "      <td>0.876102</td>\n",
       "      <td>3</td>\n",
       "      <td>0.886120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'logisticregression__C': 0.03}</td>\n",
       "      <td>0.890671</td>\n",
       "      <td>2</td>\n",
       "      <td>0.909175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'logisticregression__C': 0.04}</td>\n",
       "      <td>0.894027</td>\n",
       "      <td>1</td>\n",
       "      <td>0.915706</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            params  mean_test_score  rank_test_score  \\\n",
       "0  {'logisticregression__C': 0.01}         0.876102                3   \n",
       "1  {'logisticregression__C': 0.03}         0.890671                2   \n",
       "2  {'logisticregression__C': 0.04}         0.894027                1   \n",
       "\n",
       "   mean_train_score  \n",
       "0          0.886120  \n",
       "1          0.909175  \n",
       "2          0.915706  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This tuning section was iteratively run to search for optimal hyperparameters without overfitting.\n",
    "# I avoided single comprehensive searches as my computer was overheating and crashing.\n",
    "\n",
    "# As GridsearchCV optimizes for the best validation score, it is likely to overfit since it ignores the training score \n",
    "# in its selection. The training scores are therefore printed and included in the manual selection of the best \n",
    "# hyperparameters to use\n",
    "\n",
    "\n",
    "# 5 fold CV\n",
    "# Tokenization\n",
    "# Grid search\n",
    "\n",
    "pipeline = make_pipeline(\n",
    "        CountVectorizer(analyzer='char_wb', ngram_range=(2,ngram_upper)),\n",
    "        StandardScaler(with_mean=False),  # Sparse matrix\n",
    "        LogisticRegression(max_iter=200)\n",
    "        )\n",
    "\n",
    "parameters = {'logisticregression__C':[0.01,0.1,1]}\n",
    "lr_1 = GridSearchCV(pipeline, param_grid=parameters, cv=5, verbose=1, return_train_score=True) # Monitor for overfitting\n",
    "lr_1.fit(X_train, y_train)\n",
    "\n",
    "pd.DataFrame(lr_1.cv_results_)[['params','mean_test_score','rank_test_score','mean_train_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "different-portland",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores for tuned LR model\n",
      "Train: 0.918\n",
      "Test: 0.895\n"
     ]
    }
   ],
   "source": [
    "print(f'Scores for tuned LR model\\nTrain: {round(lr_1.score(X_train, y_train),3)}\\nTest: {round(lr_1.score(X_test, y_test),3)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "solved-animal",
   "metadata": {},
   "source": [
    "### tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "piano-private",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = make_pipeline(\n",
    "        TfidfVectorizer(analyzer='char_wb', ngram_range=(2,ngram_upper)),\n",
    "        LogisticRegression(max_iter=200)\n",
    "        )\n",
    "\n",
    "parameters = {'logisticregression__C':[0.2,0.4,1]}\n",
    "lr = GridSearchCV(pipeline, param_grid=parameters, cv=5, verbose=2, return_train_score=True) # Monitor for overfitting\n",
    "lr.fit(X_train, y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
